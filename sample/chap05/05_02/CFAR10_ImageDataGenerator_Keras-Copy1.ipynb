{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1.CIFAR-10データセットの読み込み\n",
    "'''\n",
    "from tensorflow.keras import datasets\n",
    "(x_train, t_train), (x_test, t_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,435,850\n",
      "Trainable params: 2,435,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2.畳み込みネットワークの構築\n",
    "''' \n",
    "from tensorflow.keras import models, layers, optimizers, regularizers\n",
    "\n",
    "# L2正則化の係数\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# CNNを構築\n",
    "model = models.Sequential()\n",
    "\n",
    "# (第1層)畳み込み層1 正則化を行う\n",
    "model.add(\n",
    "    layers.Conv2D(\n",
    "        filters=32,                    # フィルターの数は32\n",
    "        kernel_size=(3,3),             # 3×3のフィルターを使用\n",
    "        input_shape=x_train.shape[1:], # 入力データの形状\n",
    "        padding='same',                # ゼロパディングを行う \n",
    "        kernel_regularizer=regularizers.l2(weight_decay),\n",
    "        activation='relu'              # 活性化関数はReLU\n",
    "        ))\n",
    "\n",
    "# (第2層)プーリング層1：ウィンドウサイズは2×2\n",
    "model.add(\n",
    "    layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# (第3層)畳み込み層2　正則化を行う\n",
    "model.add(\n",
    "    layers.Conv2D(\n",
    "        filters=128,                # フィルターの数は64\n",
    "        kernel_size=(3,3),          # 3×3のフィルターを使用\n",
    "        padding='same',             # ゼロパディングを行う \n",
    "        kernel_regularizer=regularizers.l2(weight_decay),\n",
    "        activation='relu'           # 活性化関数はReLU\n",
    "        ))\n",
    "\n",
    "# (第4層)プーリング層2：ウィンドウサイズは2×2\n",
    "model.add(\n",
    "    layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# (第5層)畳み込み層3　正則化を行う\n",
    "model.add(\n",
    "    layers.Conv2D(\n",
    "        filters=256,                # フィルターの数は256\n",
    "        kernel_size=(3,3),          # 3×3のフィルターを使用\n",
    "        padding='same',             # ゼロパディングを行う \n",
    "        kernel_regularizer=regularizers.l2(weight_decay),\n",
    "        activation='relu'           # 活性化関数はReLU\n",
    "        ))\n",
    "\n",
    "# (第6層)プーリング層2：ウィンドウサイズは2×2\n",
    "model.add(\n",
    "    layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Flatten\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# ドロップアウト：ドロップアウトは40％\n",
    "model.add(layers.Dropout(0.4))\n",
    " \n",
    "# （第7層）全結合層\n",
    "model.add(\n",
    "    layers.Dense(\n",
    "        512,                   # ニューロン数は512\n",
    "        activation='relu'))    # 活性化関数はReLU\n",
    "\n",
    "\n",
    "# （第8層）出力層\n",
    "model.add(\n",
    "    layers.Dense(\n",
    "        10,                    # 出力層のニューロン数は10\n",
    "        activation='softmax')) # 活性化関数はソフトマックス\n",
    "\n",
    "# 学習率\n",
    "learning_rate = 0.1                  \n",
    "\n",
    "# Sequentialオブジェクトのコンパイル\n",
    "model.compile(\n",
    "    # 損失関数はスパースラベル対応クロスエントロピー誤差\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # オプティマイザーはSGD\n",
    "    optimizer=optimizers.SGD(lr=learning_rate),\n",
    "    # 学習評価として正解率を指定\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# モデルのサマリを表示\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 625 steps, validate for 157 steps\n",
      "Epoch 1/100\n",
      "625/625 [==============================] - 160s 256ms/step - loss: 2.0024 - accuracy: 0.2821 - val_loss: 1.6956 - val_accuracy: 0.3988\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 160s 257ms/step - loss: 1.5946 - accuracy: 0.4340 - val_loss: 1.4824 - val_accuracy: 0.4730\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 158s 253ms/step - loss: 1.4467 - accuracy: 0.4884 - val_loss: 1.3231 - val_accuracy: 0.5404\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 160s 256ms/step - loss: 1.3395 - accuracy: 0.5311 - val_loss: 1.2900 - val_accuracy: 0.5495\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 160s 257ms/step - loss: 1.2505 - accuracy: 0.5656 - val_loss: 1.1435 - val_accuracy: 0.6083\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 160s 256ms/step - loss: 1.1803 - accuracy: 0.5919 - val_loss: 1.0823 - val_accuracy: 0.6363\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 161s 257ms/step - loss: 1.1269 - accuracy: 0.6165 - val_loss: 1.0050 - val_accuracy: 0.6668\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - 162s 259ms/step - loss: 1.0728 - accuracy: 0.6345 - val_loss: 1.0690 - val_accuracy: 0.6322\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 163s 261ms/step - loss: 1.0377 - accuracy: 0.6465 - val_loss: 1.0055 - val_accuracy: 0.6542\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 164s 263ms/step - loss: 0.9961 - accuracy: 0.6640 - val_loss: 1.0749 - val_accuracy: 0.6389\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - 163s 261ms/step - loss: 0.9687 - accuracy: 0.6718 - val_loss: 0.9056 - val_accuracy: 0.6969\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - 166s 265ms/step - loss: 0.9394 - accuracy: 0.6855 - val_loss: 0.8996 - val_accuracy: 0.6976\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - 162s 258ms/step - loss: 0.9122 - accuracy: 0.6970 - val_loss: 0.8957 - val_accuracy: 0.7009\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - 161s 257ms/step - loss: 0.8938 - accuracy: 0.7032 - val_loss: 0.8766 - val_accuracy: 0.7189\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - 153s 245ms/step - loss: 0.8739 - accuracy: 0.7117 - val_loss: 0.8637 - val_accuracy: 0.7154\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - 159s 255ms/step - loss: 0.8529 - accuracy: 0.7201 - val_loss: 0.8345 - val_accuracy: 0.7257\n",
      "Epoch 17/100\n",
      "625/625 [==============================] - 160s 256ms/step - loss: 0.8373 - accuracy: 0.7246 - val_loss: 0.8182 - val_accuracy: 0.7316\n",
      "Epoch 18/100\n",
      "625/625 [==============================] - 156s 250ms/step - loss: 0.8188 - accuracy: 0.7329 - val_loss: 0.8031 - val_accuracy: 0.7433\n",
      "Epoch 19/100\n",
      "625/625 [==============================] - 156s 250ms/step - loss: 0.8062 - accuracy: 0.7380 - val_loss: 0.7892 - val_accuracy: 0.7455\n",
      "Epoch 20/100\n",
      "625/625 [==============================] - 163s 260ms/step - loss: 0.7939 - accuracy: 0.7407 - val_loss: 0.7769 - val_accuracy: 0.7473\n",
      "Epoch 21/100\n",
      "625/625 [==============================] - 157s 251ms/step - loss: 0.7763 - accuracy: 0.7484 - val_loss: 0.8479 - val_accuracy: 0.7263\n",
      "Epoch 22/100\n",
      "625/625 [==============================] - 158s 252ms/step - loss: 0.7705 - accuracy: 0.7500 - val_loss: 0.7667 - val_accuracy: 0.7568\n",
      "Epoch 23/100\n",
      "625/625 [==============================] - 159s 254ms/step - loss: 0.7541 - accuracy: 0.7558 - val_loss: 0.7774 - val_accuracy: 0.7519\n",
      "Epoch 24/100\n",
      "625/625 [==============================] - 163s 261ms/step - loss: 0.7433 - accuracy: 0.7617 - val_loss: 0.7641 - val_accuracy: 0.7582\n",
      "Epoch 25/100\n",
      "625/625 [==============================] - 165s 263ms/step - loss: 0.7274 - accuracy: 0.7680 - val_loss: 0.8030 - val_accuracy: 0.7410\n",
      "Epoch 26/100\n",
      "625/625 [==============================] - 168s 268ms/step - loss: 0.7264 - accuracy: 0.7678 - val_loss: 0.7672 - val_accuracy: 0.7633 loss: 0.7267 - \n",
      "Epoch 27/100\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 0.7161 - accuracy: 0.7736 - val_loss: 0.7425 - val_accuracy: 0.7616\n",
      "Epoch 28/100\n",
      "625/625 [==============================] - 164s 263ms/step - loss: 0.6990 - accuracy: 0.7769 - val_loss: 0.7267 - val_accuracy: 0.7743\n",
      "Epoch 29/100\n",
      "625/625 [==============================] - 180s 288ms/step - loss: 0.6974 - accuracy: 0.7780 - val_loss: 0.7594 - val_accuracy: 0.7630\n",
      "Epoch 30/100\n",
      "625/625 [==============================] - 181s 289ms/step - loss: 0.6867 - accuracy: 0.7842 - val_loss: 0.7254 - val_accuracy: 0.7739\n",
      "Epoch 31/100\n",
      "625/625 [==============================] - 185s 296ms/step - loss: 0.6766 - accuracy: 0.7868 - val_loss: 0.7274 - val_accuracy: 0.7753\n",
      "Epoch 32/100\n",
      "625/625 [==============================] - 183s 292ms/step - loss: 0.6650 - accuracy: 0.7913 - val_loss: 0.7545 - val_accuracy: 0.7661\n",
      "Epoch 33/100\n",
      "625/625 [==============================] - 184s 294ms/step - loss: 0.6652 - accuracy: 0.7925 - val_loss: 0.7137 - val_accuracy: 0.7768\n",
      "Epoch 34/100\n",
      "625/625 [==============================] - 188s 300ms/step - loss: 0.6596 - accuracy: 0.7951 - val_loss: 0.7600 - val_accuracy: 0.7635\n",
      "Epoch 35/100\n",
      "625/625 [==============================] - 179s 287ms/step - loss: 0.6535 - accuracy: 0.7973 - val_loss: 0.7167 - val_accuracy: 0.7762\n",
      "Epoch 36/100\n",
      "625/625 [==============================] - 185s 296ms/step - loss: 0.6416 - accuracy: 0.8011 - val_loss: 0.7301 - val_accuracy: 0.7717\n",
      "Epoch 37/100\n",
      "625/625 [==============================] - 169s 271ms/step - loss: 0.6392 - accuracy: 0.8046 - val_loss: 0.7417 - val_accuracy: 0.7706\n",
      "Epoch 38/100\n",
      "625/625 [==============================] - 193s 308ms/step - loss: 0.6354 - accuracy: 0.8040 - val_loss: 0.7129 - val_accuracy: 0.7828\n",
      "Epoch 39/100\n",
      "625/625 [==============================] - 191s 305ms/step - loss: 0.6203 - accuracy: 0.8093 - val_loss: 0.6847 - val_accuracy: 0.7925\n",
      "Epoch 40/100\n",
      "625/625 [==============================] - 188s 300ms/step - loss: 0.6169 - accuracy: 0.8134 - val_loss: 0.6957 - val_accuracy: 0.7879\n",
      "Epoch 41/100\n",
      "625/625 [==============================] - 196s 313ms/step - loss: 0.6118 - accuracy: 0.8117 - val_loss: 0.7229 - val_accuracy: 0.7762\n",
      "Epoch 42/100\n",
      "625/625 [==============================] - 203s 324ms/step - loss: 0.6073 - accuracy: 0.8139 - val_loss: 0.7042 - val_accuracy: 0.7892\n",
      "Epoch 43/100\n",
      "625/625 [==============================] - 198s 317ms/step - loss: 0.6037 - accuracy: 0.8177 - val_loss: 0.7085 - val_accuracy: 0.7894\n",
      "Epoch 44/100\n",
      "625/625 [==============================] - 185s 296ms/step - loss: 0.6005 - accuracy: 0.8184 - val_loss: 0.7088 - val_accuracy: 0.7852\n",
      "Epoch 45/100\n",
      "625/625 [==============================] - 192s 307ms/step - loss: 0.5907 - accuracy: 0.8225 - val_loss: 0.7066 - val_accuracy: 0.7903\n",
      "Epoch 46/100\n",
      "625/625 [==============================] - 188s 301ms/step - loss: 0.5953 - accuracy: 0.8242 - val_loss: 0.7437 - val_accuracy: 0.7706\n",
      "Epoch 47/100\n",
      "625/625 [==============================] - 185s 296ms/step - loss: 0.5835 - accuracy: 0.8257 - val_loss: 0.6794 - val_accuracy: 0.7956\n",
      "Epoch 48/100\n",
      "625/625 [==============================] - 184s 294ms/step - loss: 0.5775 - accuracy: 0.8262 - val_loss: 0.7237 - val_accuracy: 0.7821\n",
      "Epoch 49/100\n",
      "625/625 [==============================] - 184s 295ms/step - loss: 0.5783 - accuracy: 0.8272 - val_loss: 0.6774 - val_accuracy: 0.7965\n",
      "Epoch 50/100\n",
      "625/625 [==============================] - 196s 313ms/step - loss: 0.5689 - accuracy: 0.8320 - val_loss: 0.6858 - val_accuracy: 0.7974\n",
      "Epoch 51/100\n",
      "625/625 [==============================] - 194s 310ms/step - loss: 0.5688 - accuracy: 0.8322 - val_loss: 0.6719 - val_accuracy: 0.8024\n",
      "Epoch 52/100\n",
      "625/625 [==============================] - 197s 315ms/step - loss: 0.5654 - accuracy: 0.8338 - val_loss: 0.6700 - val_accuracy: 0.8016\n",
      "Epoch 53/100\n",
      "625/625 [==============================] - 192s 306ms/step - loss: 0.5521 - accuracy: 0.8378 - val_loss: 0.6896 - val_accuracy: 0.7954\n",
      "Epoch 54/100\n",
      "625/625 [==============================] - 184s 295ms/step - loss: 0.5553 - accuracy: 0.8358 - val_loss: 0.6929 - val_accuracy: 0.7990\n",
      "Epoch 55/100\n",
      "625/625 [==============================] - 197s 315ms/step - loss: 0.5591 - accuracy: 0.8351 - val_loss: 0.6899 - val_accuracy: 0.7999\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 200s 320ms/step - loss: 0.5469 - accuracy: 0.8407 - val_loss: 0.7169 - val_accuracy: 0.7856\n",
      "Epoch 57/100\n",
      "625/625 [==============================] - 191s 305ms/step - loss: 0.5518 - accuracy: 0.8395 - val_loss: 0.7017 - val_accuracy: 0.7909\n",
      "Epoch 58/100\n",
      "625/625 [==============================] - 194s 310ms/step - loss: 0.5474 - accuracy: 0.8406 - val_loss: 0.7000 - val_accuracy: 0.7966\n",
      "Epoch 59/100\n",
      "625/625 [==============================] - 191s 306ms/step - loss: 0.5439 - accuracy: 0.8443 - val_loss: 0.6942 - val_accuracy: 0.7987\n",
      "Epoch 60/100\n",
      "625/625 [==============================] - 191s 305ms/step - loss: 0.5404 - accuracy: 0.8441 - val_loss: 0.6580 - val_accuracy: 0.8091\n",
      "Epoch 61/100\n",
      "625/625 [==============================] - 197s 315ms/step - loss: 0.5384 - accuracy: 0.8461 - val_loss: 0.6815 - val_accuracy: 0.7999\n",
      "Epoch 62/100\n",
      "625/625 [==============================] - 189s 302ms/step - loss: 0.5342 - accuracy: 0.8469 - val_loss: 0.6870 - val_accuracy: 0.8038\n",
      "Epoch 63/100\n",
      "625/625 [==============================] - 184s 294ms/step - loss: 0.5323 - accuracy: 0.8489 - val_loss: 0.6845 - val_accuracy: 0.7982\n",
      "Epoch 64/100\n",
      "237/625 [==========>...................] - ETA: 2:42 - loss: 0.5118 - accuracy: 0.8537"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "3.学習の実行\n",
    "'''\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ミニバッチのサイズ\n",
    "batch_size = 64\n",
    "\n",
    "# データ拡張\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,      # ピクセル値を255で割って正規化する\n",
    "    validation_split=0.2,   # 20パーセントのデータを検証用にする\n",
    "    rotation_range=15,      # 15度の範囲でランダムに回転させる\n",
    "    width_shift_range=0.1,  # 横サイズの0.1の割合でランダムに水平移動\n",
    "    height_shift_range=0.1, # 縦サイズの0.1の割合でランダムに垂直移動\n",
    "    horizontal_flip=True,  # 水平方向にランダムに反転、左右の入れ替え\n",
    "    zoom_range=0.2,         # ランダムに拡大\n",
    ")\n",
    "\n",
    "# 訓練データ用のジェネレーターを生成\n",
    "training_generator = datagen.flow(x_train, t_train,\n",
    "                                  batch_size=batch_size,\n",
    "                                  subset='training')      # 訓練用のデータを生成\n",
    "# 検証データ用のジェネレーターを生成\n",
    "validation_generator = datagen.flow(x_train, t_train,\n",
    "                                    batch_size=batch_size,\n",
    "                                    subset='validation') # 検証用のデータを生成\n",
    "# エポック数\n",
    "epochs = 100\n",
    "\n",
    "# 学習を行う\n",
    "history = model.fit(\n",
    "    # 拡張データをミニバッチの数だけ生成\n",
    "    training_generator,\n",
    "    epochs=epochs,         # エポック数\n",
    "    verbose=1,             # 学習の進捗状況を出力する\n",
    "    validation_data=validation_generator,  # 20パーセントのデータを検証に使用\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4.損失と精度の推移をグラフにする\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_history(history):\n",
    "    # 精度の履歴をプロット\n",
    "    plt.plot(history.history['accuracy'],\"-\",label=\"accuracy\")\n",
    "    plt.plot(history.history['val_accuracy'],\"-\",label=\"val_acc\")\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # 損失の履歴をプロット\n",
    "    plt.plot(history.history['loss'],\"-\",label=\"loss\",)\n",
    "    plt.plot(history.history['val_loss'],\"-\",label=\"val_loss\")\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "# modelに学習させた時の変化の様子をplot\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5. テストデータによるモデルの評価\n",
    "'''\n",
    "# テストデータを正規化\n",
    "x_test = x_test / 255\n",
    "\n",
    "# 学習済みのモデルにテストデータを入力して損失と精度を取得\n",
    "test_loss, test_acc = model.evaluate(x_test, t_test, verbose=0)\n",
    "print('test_loss:', test_loss)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
